# Module 7: LLM Audit Trail

> Spec for **{{app_name}}** -- generated by Launchblocks

## Purpose

The LLM Audit Trail provides a complete, tamper-resistant record of every LLM call made through the gateway. It powers an admin dashboard for monitoring usage, tracking costs, reviewing errors, and exporting data. Every request logged by the LLM Gateway (Module 5) is surfaced here with filtering, aggregation, and visualization.

## Authorization

| Action | Required Permission | Roles |
|---|---|---|
| View audit dashboard | `view_audit_log` | {{#each role_permission_summary}}{{#if has_permissions}}{{this.name}}{{#unless @last}}, {{/unless}}{{/if}}{{/each}} |
| Export audit data to CSV | `export_audit_log` | {{#each role_permission_summary}}{{#if has_permissions}}{{this.name}}{{#unless @last}}, {{/unless}}{{/if}}{{/each}} |
| View own usage | (any authenticated user) | {{role_names_joined}} |

Note: Individual users can always see their own audit entries (the `audit_select_own` RLS policy). The admin dashboard and export features require explicit permissions.

## Database Schema

The audit trail reads from two sources created in migration `004_llm_audit_log`:

### `llm_audit_log` Table

| Column | Type | Description |
|---|---|---|
| `id` | uuid | Primary key |
| `user_id` | uuid | FK to `user_profiles.id` -- who made the call |
| `prompt_template_id` | uuid | FK to `prompt_templates.id` -- null for ad-hoc calls |
| `provider` | text | Provider used ({{#each providers_display}}`{{this.id}}`{{#unless @last}}, {{/unless}}{{/each}}) |
| `model` | text | Model name used |
| `input_tokens` | integer | Tokens in the request |
| `output_tokens` | integer | Tokens in the response |
| `total_tokens` | integer | Generated column: `input_tokens + output_tokens` |
| `estimated_cost` | numeric(10,6) | Estimated USD cost of the call |
| `latency_ms` | integer | Round-trip time in milliseconds |
| `status` | text | `"success"`, `"error"`, or `"timeout"` |
| `error_message` | text | Error details (null on success) |
| `request_metadata` | jsonb | Structural metadata (template slug, model config, etc.) |
| `created_at` | timestamptz | When the call was made |

### `llm_audit_summary` View

Pre-aggregated data for dashboard charts, grouped by day, provider, and model:

| Column | Type | Description |
|---|---|---|
| `day` | timestamptz | Truncated to day |
| `provider` | text | Provider name |
| `model` | text | Model name |
| `request_count` | bigint | Number of calls |
| `total_input_tokens` | bigint | Sum of input tokens |
| `total_output_tokens` | bigint | Sum of output tokens |
| `total_tokens` | bigint | Sum of all tokens |
| `total_cost` | numeric | Sum of estimated costs |
| `avg_latency_ms` | integer | Average response time |
| `error_count` | bigint | Number of failed calls |

Use this view for dashboard charts instead of querying the raw log table -- it is significantly faster for time-series data.

## Dashboard Metrics

The audit dashboard displays the following key metrics, each derived from the data sources above.

### Summary Cards (Top of Dashboard)

Display these as prominent metric cards at the top of the page:

| Metric | Calculation | Description |
|---|---|---|
| Total Calls | `COUNT(*)` from `llm_audit_log` | Total number of LLM calls |
| Total Tokens | `SUM(total_tokens)` | Combined input + output tokens |
| Total Cost | `SUM(estimated_cost)` | Estimated USD spent |
| Error Rate | `COUNT(*) WHERE status != 'success' / COUNT(*)` | Percentage of failed calls |
| Avg Latency | `AVG(latency_ms)` | Average response time |

Each card should show the value for the selected date range and a comparison to the previous period (e.g., "+12% vs. last 7 days").

### Breakdown Tables

Below the summary cards, show breakdowns:

**By Provider:**
| Provider | Calls | Tokens | Cost | Errors |
|---|---|---|---|---|
{{#each providers_display}}
| {{this.name}} | -- | -- | -- | -- |
{{/each}}

**By Model:**
Show the top 10 models by call count with the same columns.

**By User:**
Show the top 10 users by call count with columns: User, Role, Calls, Tokens, Cost.

## Filtering

The dashboard and API support filtering by:

| Filter | Type | Description |
|---|---|---|
| Date range | `start_date`, `end_date` | Filter by `created_at` range |
| Provider | `provider` | Single or multi-select from: {{#each providers_display}}`{{this.id}}`{{#unless @last}}, {{/unless}}{{/each}} |
| Model | `model` | Single or multi-select (populated dynamically from data) |
| User | `user_id` | Filter to a specific user |
| Status | `status` | `success`, `error`, `timeout`, or all |
| Template | `prompt_template_id` | Filter by specific template |

### Preset Date Ranges

Provide quick-select buttons: Today, Last 7 Days, Last 30 Days, This Month, Last Month, Custom Range.

## Cost Tracking

### How Costs Are Calculated

The LLM Gateway calculates `estimated_cost` at the time of each call using the formula:

```
estimated_cost = (input_tokens / 1,000,000 * input_price) + (output_tokens / 1,000,000 * output_price)
```

Per-model pricing is stored in the application config (see `references/llm-pricing-table.md`). Costs are estimates -- actual billing from providers may differ slightly due to rounding.

### Cost Dashboard Elements

1. **Total cost for selected period** -- displayed prominently as a summary card
2. **Daily cost trend chart** -- line chart from `llm_audit_summary` showing cost per day
3. **Cost by provider** -- pie or bar chart showing cost distribution
4. **Cost by model** -- bar chart showing which models cost the most
5. **Cost by user** -- table showing top users by cost (helps identify outliers)
6. **Projected monthly cost** -- extrapolate current usage to estimate the full month

### Cost Alerts (Recommended)

While not required for the initial implementation, consider adding threshold alerts:
- Daily cost exceeds $X
- Single user exceeds $Y in a day
- Error rate exceeds Z%

These can be implemented as a background check that runs on each audit log insert.

## Per-User Usage Tracking

Each authenticated user can view their own LLM usage on a personal usage page (e.g., `/dashboard/usage`). This page does not require any special permission -- the `audit_select_own` RLS policy restricts the query to the user's own rows.

### User Usage Page

- **My Total Calls** / **My Total Tokens** / **My Total Cost** summary cards
- **My Recent Calls** table: date, template used (or "ad-hoc"), model, tokens, cost, status
- Paginated, most recent first
- Click a row to see details (model, latency, error message if failed)

This page gives users visibility into their own LLM consumption without needing admin access.

## Error Log Review

The admin dashboard includes an error-focused view for debugging failed LLM calls.

### Error Log View

Filter the audit log to `status IN ('error', 'timeout')` and display:

| Column | Description |
|---|---|
| Timestamp | When the error occurred |
| User | Who triggered the call |
| Provider | Which provider failed |
| Model | Which model was requested |
| Status | `error` or `timeout` |
| Error Message | The captured error detail |
| Latency | How long before the error (useful for timeout diagnosis) |
| Template | Which template was used (if any) |

### Error Patterns to Watch For

- **Repeated timeouts** on a specific model -- may indicate provider issues
- **Authentication errors** -- API key may be invalid or expired
- **Rate limit errors** -- may need to implement queuing or backoff
- **Model not found** -- template references a deprecated model

## Charts and Visualizations

Recommended charts for the audit dashboard (implement using a charting library like Recharts, Chart.js, or similar):

### 1. Daily Usage Over Time (Line Chart)
- X-axis: date
- Y-axis: request count (left) and cost (right)
- Source: `llm_audit_summary` view
- One line per provider{{#if has_multiple_providers}} to compare usage across providers{{/if}}

### 2. Token Distribution (Stacked Bar Chart)
- X-axis: date
- Y-axis: token count
- Stacked bars: input tokens vs. output tokens
- Source: `llm_audit_summary` view

### 3. Cost by Provider (Pie/Donut Chart)
- Segments: one per provider
- Values: total cost for the selected period
- Source: `llm_audit_summary` view grouped by provider

### 4. Latency Distribution (Histogram)
- X-axis: latency buckets (0-500ms, 500-1000ms, 1-2s, 2-5s, 5s+)
- Y-axis: request count
- Source: `llm_audit_log` table
- Helps identify performance outliers

### 5. Error Rate Over Time (Line Chart)
- X-axis: date
- Y-axis: error percentage
- Source: `llm_audit_summary` view (error_count / request_count)

## Export to CSV

Users with the `export_audit_log` permission can export filtered audit data to CSV.

### Export Endpoint: `GET /api/admin/audit/export`

**Query parameters:** Same filters as the dashboard (date range, provider, model, user, status).

**Response:** `Content-Type: text/csv` with `Content-Disposition: attachment; filename="llm-audit-export-YYYY-MM-DD.csv"`

**CSV columns:**
```
id,timestamp,user_email,provider,model,input_tokens,output_tokens,total_tokens,estimated_cost,latency_ms,status,error_message,template_slug
```

### Export Implementation Notes

- Stream the CSV response for large datasets (do not load all rows into memory)
- Limit exports to a maximum of 100,000 rows per request
- Include a header row
- Format timestamps as ISO 8601
- Format cost as decimal with 6 places (e.g., `0.003215`)
- Join with `user_profiles` for email and `prompt_templates` for slug
- Log the export action itself (who exported, when, what filters were applied)

## API Endpoints

### `GET /api/admin/audit`

List audit log entries with filtering and pagination.

**Query parameters:**
- `start_date` -- ISO 8601 date (inclusive)
- `end_date` -- ISO 8601 date (inclusive)
- `provider` -- filter by provider
- `model` -- filter by model
- `user_id` -- filter by user
- `status` -- filter by status
- `template_id` -- filter by prompt template
- `page` -- page number (default 1)
- `per_page` -- items per page (default 50, max 200)

**Response:**
```json
{
  "entries": [
    {
      "id": "uuid",
      "user_id": "uuid",
      "user_email": "user@example.com",
      "user_name": "John Doe",
      "prompt_template_id": "uuid",
      "template_slug": "summarize-article",
      "provider": "{{providers_display.[0].id}}",
      "model": "gpt-4o",
      "input_tokens": 142,
      "output_tokens": 287,
      "total_tokens": 429,
      "estimated_cost": 0.003215,
      "latency_ms": 1823,
      "status": "success",
      "error_message": null,
      "created_at": "2025-01-20T14:22:00Z"
    }
  ],
  "total": 15234,
  "page": 1,
  "per_page": 50
}
```

### `GET /api/admin/audit/summary`

Get aggregated metrics for the dashboard summary cards and charts.

**Query parameters:** `start_date`, `end_date`, `provider`, `model`, `user_id`

**Response:**
```json
{
  "totals": {
    "calls": 15234,
    "input_tokens": 4521000,
    "output_tokens": 2103000,
    "total_tokens": 6624000,
    "total_cost": 48.52,
    "avg_latency_ms": 1420,
    "error_count": 87,
    "error_rate": 0.0057
  },
  "by_day": [
    {
      "day": "2025-01-20",
      "request_count": 523,
      "total_tokens": 234000,
      "total_cost": 1.82,
      "error_count": 3
    }
  ],
  "by_provider": [
    {{#each providers_display}}
    {
      "provider": "{{this.id}}",
      "request_count": 0,
      "total_tokens": 0,
      "total_cost": 0
    }{{#unless @last}},{{/unless}}
    {{/each}}
  ],
  "by_model": [],
  "by_user": []
}
```

### `GET /api/admin/audit/export`

Export audit data to CSV. See the "Export to CSV" section above for details.

**Requires:** `export_audit_log` permission.

### `GET /api/user/audit` (Personal Usage)

List the current user's own audit entries. No special permission required -- RLS handles access control.

**Query parameters:** Same as `/api/admin/audit` except no `user_id` (always scoped to the authenticated user).

## Admin UI Pages

### Audit Dashboard (`/admin/audit`)

Layout:

1. **Date range selector** with preset buttons at the top
2. **Filter bar** with provider, model, user, and status dropdowns
3. **Summary cards row** -- Total Calls, Total Tokens, Total Cost, Error Rate, Avg Latency
4. **Charts section** -- Daily Usage line chart and Cost by Provider pie chart side by side
5. **Log table** -- paginated list of individual audit entries
6. **Export button** in the top-right corner

### Error Review (`/admin/audit?status=error`)

Same page as the main dashboard but pre-filtered to errors and timeouts. The log table highlights error messages in red.

### User Usage (`/dashboard/usage`)

Simplified version of the dashboard scoped to the current user. No admin permission required.

## Implementation Tasks

Complete these tasks in order. Each task builds on the previous ones.

### Task 7.1: Build Audit List API
Implement `GET /api/admin/audit` with filtering (date range, provider, model, user, status, template) and pagination. Join with `user_profiles` for email/name and `prompt_templates` for slug.
**Verify:** Call the API with default parameters and confirm paginated audit entries are returned with user and template details.

### Task 7.2: Build Audit Summary API
Implement `GET /api/admin/audit/summary` using the `llm_audit_summary` view. Return totals (calls, tokens, cost, error rate, avg latency), by_day, by_provider, by_model, and by_user breakdowns.
**Verify:** Call the summary API and confirm the totals match the raw data in `llm_audit_log`.

### Task 7.3: Build CSV Export API
Implement `GET /api/admin/audit/export` that streams a CSV response. Include columns: id, timestamp, user_email, provider, model, input_tokens, output_tokens, total_tokens, estimated_cost, latency_ms, status, error_message, template_slug. Limit to 100,000 rows.
**Verify:** Call the export endpoint and confirm a valid CSV file is downloaded with correct headers and data.

### Task 7.4: Build Personal Usage API
Implement `GET /api/user/audit` that returns the current user's own audit entries. No special permission required — RLS handles scoping.
**Verify:** Call the API as a regular user and confirm only their own audit entries are returned.

### Task 7.5: Add Permission Middleware
Add `view_audit_log` permission check to admin audit routes. Add `export_audit_log` check to the export route. Personal usage route requires only authentication.
**Verify:** A user without `view_audit_log` receives 403 on admin audit routes. Any authenticated user can access personal usage.

### Task 7.6: Build Dashboard Page with Summary Cards
Create `/admin/audit` with date range selector (preset buttons: Today, Last 7 Days, Last 30 Days, Custom), filter bar (provider, model, user, status), and summary metric cards (Total Calls, Total Tokens, Total Cost, Error Rate, Avg Latency).
**Verify:** The dashboard loads with correct summary metrics for the selected date range.

### Task 7.7: Integrate Charts
Add a charting library (Recharts, Chart.js, or similar) and build the recommended charts: Daily Usage Over Time, Token Distribution, Cost by Provider, Latency Distribution, and Error Rate Over Time.
**Verify:** Charts render with data from the summary API and update when filters change.

### Task 7.8: Build Filterable Log Table
Add a paginated table of individual audit entries below the charts. Columns: Timestamp, User, Template, Provider, Model, Tokens (in/out), Cost, Latency, Status. Support sorting by any column.
**Verify:** The table loads with paginated data, filters match the dashboard filters, and sorting works on all columns.

### Task 7.9: Build CSV Export Functionality
Add an "Export" button to the dashboard that downloads filtered audit data as CSV. Pass current filters to the export endpoint. Show a loading indicator during download.
**Verify:** Apply filters, click Export, and confirm the downloaded CSV contains only the filtered data.

### Task 7.10: Build Personal Usage Page
Create `/dashboard/usage` with summary cards (My Total Calls, My Total Tokens, My Total Cost) and a table of recent LLM calls. No admin permission required.
**Verify:** A regular user sees their own usage data. The page does not show other users' data.

### Task 7.11: Build Error Review View
Add error-focused filtering (pre-filter to `status IN ('error', 'timeout')`) accessible via `/admin/audit?status=error`. Highlight error messages in red in the log table.
**Verify:** Navigate to the error view and confirm only error and timeout entries are displayed.

---

## Test Specifications

### Unit Tests
- [ ] Date range filter correctly converts preset labels to start/end dates
- [ ] CSV formatter correctly escapes commas and quotes in field values
- [ ] CSV formatter formats timestamps as ISO 8601
- [ ] CSV formatter formats cost with 6 decimal places
- [ ] Pagination calculates correct offset and limit from page/per_page params
- [ ] Summary card calculations match expected aggregations

### Integration Tests
- [ ] Audit list API returns entries filtered by date range
- [ ] Audit list API returns entries filtered by provider
- [ ] Audit list API returns entries filtered by status
- [ ] Audit list API returns entries filtered by user_id
- [ ] Audit list API joins user email and template slug correctly
- [ ] Audit summary API returns correct totals matching raw data
- [ ] Audit summary `by_day` breakdown matches daily aggregation from the view
{{#if has_multiple_providers}}
- [ ] Audit summary `by_provider` breakdown shows data for each configured provider
{{/if}}
- [ ] CSV export streams data without loading all rows into memory
- [ ] CSV export respects the 100,000 row limit
- [ ] CSV export includes correct headers
- [ ] Personal usage API returns only the authenticated user's entries (RLS enforced)
- [ ] `view_audit_log` permission is required for admin audit routes
- [ ] `export_audit_log` permission is required for the export route

### E2E Tests
- [ ] Admin opens audit dashboard → sees summary cards with correct data → charts render
- [ ] Admin applies date range filter → summary cards and charts update → log table filters
- [ ] Admin applies provider filter → all dashboard components reflect the filter
- [ ] Admin clicks Export → CSV downloads with filtered data → file opens correctly in spreadsheet
- [ ] Admin switches to error view → only error/timeout entries shown
- [ ] Regular user opens personal usage page → sees only their own calls
- [ ] Regular user cannot access `/admin/audit` (redirected or shown 403)
